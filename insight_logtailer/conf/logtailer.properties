# logtailer自身的状态，汇报到那个kakfa的哪个topic
monitor.enable = true
monitor.topic = sahara_stat

# 多少ms汇报一次自身状态
# 10s一次，则每天会产生8640条记录，每条假定1k，则14天的数据是，14*8M=112M。
# 假定有100台机器（实例），则14天总共约11G。这些数据是放在kafka的broker上的
# 数据最终在mysql保存最后的状态，并在web上展示
monitor.interval.ms = 10000

# kafka的producer需要的broker.list
# 如果不填写，会默认查找线上线下默认的kafka服务
# 一般情况无需填写
#monitor.kafka.server.list=

# name of the partitioner class for partitioning events; default partition spreads data randomly
#partitioner.class=

# specifies whether the messages are sent asynchronously (async) or synchronously (sync)
producer.type=async

# specify the compression codec for all data generated: 0: no compression, 1: gzip
compression.codec=0

# message encoder
#serializer.class=kafka.serializer.StringEncoder
serializer.class=kafka.serializer.DefaultEncoder

# allow topic level compression
#compressed.topics=

# max message size; messages larger than that size are discarded; default is 1000000
#max.message.size=


############################# Async Producer #############################
# 以下配置无特殊需求不需要指定，使用默认即可

# maximum time, in milliseconds, for buffering data on the producer queue
#queue.time=

# the maximum size of the blocking queue for buffering on the producer
#queue.size=

# Timeout for event enqueue:
# 0: events will be enqueued immediately or dropped if the queue is full
# -ve: enqueue will block indefinitely if the queue is full
# +ve: enqueue will block up to this many milliseconds if the queue is full
#queue.enqueueTimeout.ms=

# the number of messages batched at the producer
#batch.size=

# the callback handler for one or multiple events
#callback.handler=

# properties required to initialize the callback handler
#callback.handler.props=

# the handler for events
#event.handler=

# properties required to initialize the event handler
#event.handler.props=
